To address the question regarding data scraping and analysis of the highest-grossing films from the provided Wikipedia URL, we will extract the necessary parameters and outline the steps for implementation. 

### Extracted Parameters:
1. **URL**: 
   - `url`: "https://en.wikipedia.org/wiki/List_of_highest-grossing_films"

2. **Sub-questions**:
   - **Question 1**: 
     - `release_year_threshold`: 2020
     - `gross_threshold_1`: 2_000_000_000 (2 billion)
   - **Question 2**: 
     - `gross_threshold_2`: 1_500_000_000 (1.5 billion)
   - **Question 3**: 
     - `correlation_parameters`: ["Rank", "Peak"]
   - **Question 4**: 
     - `scatterplot_parameters`: ["Rank", "Peak"]
     - `regression_line_color`: "red"
     - `output_format`: "base64"
     - `max_output_size`: 100_000 bytes

### Expected Output Type:
- The output for the answers to the specified sub-questions will be structured as a JSON array of strings.
- The scatterplot will be returned as a base-64 encoded data URI.

### Planned Steps:
1. **Data Scraping**:
   - Use a web scraping library (e.g., BeautifulSoup) to extract the table of highest-grossing films from the specified URL.
   - Parse the relevant data, including film titles, gross earnings, release years, ranks, and peak positions.

2. **Data Analysis**:
   - **For Question 1**: Filter the scraped data to count the number of films that grossed over $2 billion and were released before 2020.
   - **For Question 2**: Identify the earliest film that grossed over $1.5 billion by sorting the data based on release year and filtering by gross earnings.
   - **For Question 3**: Calculate the correlation between the Rank and Peak values using a statistical library (e.g., NumPy or Pandas).
   - **For Question 4**: Create a scatterplot of Rank vs. Peak using a plotting library (e.g., Matplotlib), and add a dotted red regression line. Convert the plot to a base-64 encoded data URI.

3. **Output Formatting**:
   - Compile the results of the analyses into a JSON array of strings, ensuring that each answer is formatted correctly.

By following these steps, we will be able to effectively scrape the required data, perform the necessary analyses, and return the results in the specified format.